> Emplacement du code du TP : 
> `Student_Cuda_Image/src/cpp/core/01_Rippling/`
> Main : `Student_Cuda_Image/src/cpp/main.cpp`

# Notes de S√©bastien
> j'√©tait absent au d√©but

D√©river de la m√©thode Animable_I<uchar4>

Une couleur en Java : `int` : 4 octets : `[ R | G | B | A ]`

En Cuda: `uchar` (unsigned char) : 1 octet
Mais aussi `uchar4` (unsigned char 4 bytes) : 4 octets

S'imaginer que le type est impl√©ment√© comme √ßa :

```cpp
struct uchar4 {
    uchar x; // Composante R
    uchar y; // Composante G
    uchar z; // Composante B
    uchar w; // Composante A
}
```


Convention utilis√©e : **Row major** :
```cpp
[1, 2, 3,
 4, 5, 6]
```

le tableau est stock√© sur 1 dimension, donc on a :
```cpp
[1, 2, 3, 4, 5, 6]
```

avec `w = 3` (largeur) et `h = 2` (hauteur)

```cpp
// GPU
void process(uchar4* tabPixelsGM, uint w, uint h, float t) {
    ...
}
```

`DomainMath` --> on fait rien avec pour l'instant

```cpp
// GPU
void animationStep() {
    ...
}
```

---- 

Objectif pour la semaine prochaine : **Rippling (Cuda)**
Temps estim√© pour la r√©alisation : 30 min (15 min pour ceux qui sont rapides)
Aucune r√©duction √† utiliser

> "Maintenant il y a plus qu'a"
> ~ Bilat, 2023


--- 

La m√©thode `void Indices::toIJ(s, w, &i, &j)` permet la conversion de `s` (l'indice dans le thread) vers `i` (position Y) et `j` (position X)
Il faut faire :
```cpp
#include "Indices.cu.h"
```
 pour pouvoir utiliser la m√©thode utilitaire (d√©j√† inclu) 
Pour colorier un pixel : `void ripplingMath.colorIJ(&tabPixelsGM[s], i, j)` (pas oublier le `&` vu que la m√©thode √©crit dans la case)

# Mes notes

!!! info "Boite √† outil" d'execution
    Si les executions "eclipses" n'apparaissent pas dans les outils, afficher les "externals"
    ![](Screen/2023-03-28-15-39-59.png)

## Tuer des executions CUDA "perdues"
![](Screen/2023-03-28-15-37-31.png)

Si une erreur "no process found" apparait dans la console, c'est qu'aucun processus n'√©tait en cours, donc c'est bon üòÑ  

## Le mode "affichage" (`Image`)
```cpp
// Student_Cuda_Image/src/cpp/main.cpp
udaContext.launchMode = LaunchModeImage::IMAGE;
```

Pour executer ce mode, il faut lancer le programme avec `GL`
![](Screen/2023-03-28-15-21-10.png)

!!! info L'execution avec "GL" permet d'ajouter un proxy au pipeline d'OpenGL :
    OpenGL va afficher directement sur l'√©cran de l'appareil, sauf que l√† on est sur un serveur sans √©cran !
    Le fait d'ajouter un proxy, les donn√©es qui devrait √™tre affich√©es sur un √©cran sont sauv√©e au format `.png` puis envoy√©s sur le r√©seau. Cette image est ensuite affich√©e sur la fen√™tre dans notre VM.

Ce mode permet de lancer l'execution en mode graphie. On peut y voir des FPS.
- Ces FPS ne sont pas ceux qu'il faut atteindre pour les rendus !
- Les FPS affich√©s sont ceux du **Pipeline total** (contenant : `calcul kernel cuda` + `pipeline OpenGL` + `envoie sur le r√©seau`.
- Pour le Rippling, on a par exemple `17FPS`, bien loins des `183K` souhait√©)

## Mode "Benchmark" (`Benchmark`)
```cpp
// Student_Cuda_Image/src/cpp/main.cpp
cudaContext.launchMode = LaunchModeBenchmark::BENCHMARK;
```

Le code n'est plus execut√© pour √™tre affich√©s, ainsi on peut mesurer les FPS du kernel CUDA.

Comme on a plus d'affichage, il faut plus lancer avec `GL` :

![](Screen/2023-03-28-15-26-49.png)

### Maximiser les FPS en CUDA
- float et pas double (on passe de 100K FPS √† 10K si on utilise des FPS)
- Limiter le nombre de conversions (exemple de float en int)
- Heuristique : si c'est pas "ou un multiple", les perfo sont nulles
  - Il faudra souvant faire un multiple et pas juste prendre la valeur (voir "Bruteforce")

!!! info Les meilleurs perfs
    en g√©n√©ral, le GPU#2 est plus rapide que le 1, car il est plus √©loign√© (et donc plus froid) (sauf si tout le monde l'utilise üòÜ)

    Par contre, le prof ne se basera pas sur celui-ci pour l'√©valuation ü•≤

## Mode "Bruteforce" (`Bruteforce`)
```cpp
// Student_Cuda_Image/src/cpp/main.cpp
cudaContext.launchMode = LaunchModeBruteforce::BRUTEFORCE;
```

Pour chercher les meilleurs grilles : utiliser `BRUTEFORCE` (au lieu de `BENCHMARKING`)
Il va tester plusieurs grilles (respectant l'heuristique)

Ensuite, les statistiques sont affich√©s via MathLab. Plus les donn√©es sont jaunes, plus les FPS sont bien !

Le meilleur r√©sultat est affich√© en rouge.

**Remarque** :
Ne pas prendre forcement le meilleur r√©sultat fournis par le bruteforce, mais celles qui sont plus constants (pour limiter les variations) 
> Ne pas "prendre" au "bords" d'une "chemin√©e", mais plut√¥t une valeur en "plaine"

## Remarques diverses

### Rappel des valeurs des heuristiques

DB == 64 √† 1024 (puissance de 2)
DG == multiples de 68

### Variations entre les executions

Les diff√©rences de FPS obtenus d'une execution √† l'autre sont dues aux variations de fr√©quences de GPU.

Si on lance, le GPU augmente ses fr√©quences, et quand elles atteignes le max elle reste un moment, une fois moins solicit√©, le GPU bride les performances ce qui les fait vari√© (mont√©-descente)
Une fois plus utilis√©, la fr√©quence red√©scend au min avant de pouvoir relancer un nouveau cycle full perf


# TP Rippling Cuda

-  atteindre 183K FPS (175K est acceptable, comme beaucoup de monde travail en m√™me temps) (le seuil minimal est de 160K)
- Si on a un thread (grille 1,1,1) : On a quoi en FPS ? 
Chasse aux FPS : configuration de la grille (√† tester diff√©rentes valeurs)
- Lire le PDF, il y a des "b√©tises" dans le code qu'il faut exp√©riment√© üôÇ (et les document√©s, pour √©viter de les commettre dans les futures TP)

Il est possible d'am√©liorer les FPS (pour atteindre ~240K) en r√©duisant le nombre d'informations calcul√©es :
- il est possible de calculer qu'une partie de l'image, √©tant donn√© que l'image est "sym√©trique"
- (optimisation par quart est plus complexe que par moiti√© "horizontale" √† mettre en place, car y a plus de calcul de sym√©trie et comme chaque thread doit avoir le m√™me code)