<!-- #region NOTE BLOCK --> 
<div style="margin: 20px auto; padding: 10px; background-color: #ffd48a; border-left: 5px solid #8a5700;color: black; font-size: 2em">
<span> ðŸ“‘ </span>Note<br>
<span style="font-size: 0.75em">

Cette version n'est pas la plus optimale.
Cours du [2023-03-14](2023-03-14-Labo-SliceSM.md) pour la version optimale.
</span></div>

<!-- #endregion NOTE BLOCK -->



# RÃ©duction additive (`RÃ©duction +`) inplace

Pour nos algorithmes, on va travailler avec `n = 2^k`, avec `n == nombre de thread` (choisi par nous)

Puissance de 2 implique la possibilitÃ© de couper le tableau par 2 de sÃ»re.

On rÃ©pÃ¨te l'opÃ©ration `m` fois :
`m = n/2 = n >> 1` (il n'y a pas plus rapide qu'un opÃ©rateur de dÃ©calage de bits)
Tant que `m > 0` :

![algo rÃ©duction additive avec Ã©crasement](./Export/algo-reduction-additive.svg)
> On remarque qu'a chaque fois on a besoin de moins de thread pour la mise en place du parallÃ©lisme.
> Les autres sont mis au "chÃ´mage"
> On vois que le thread "vert" va travailler 1x de plus que le bleu, 2x de plus que le rouge et orange, etc.

> Algorithmes rÃ©cursif sont bienb moins performants.
> Ici on cherche la performance, donc on utilise un algorithme itÃ©ratif.

## Algorithme CPP

```cpp
void reduce(float* tab, int n)
{
	int m = n >> 1;

	while (m > 0)
	{
		ecrasement(tab, m);
		m = m >> 1;
	}
}


void ecrasement (float* tab, int m)
{
	for (int i = 0; i < m; i++)
	{
		tab[i] = tab[i] + tab[i + m]
	}
}
```

## ProblÃ¨mes de concurrence

Si l'on reprend le schÃ©ma, on remarque qu'il y a un problÃ¨me de concurrence. On ne peut pas passer au `m` suivant tant que l'Ã©crasement prÃ©cÃ©dent n'est pas terminÃ©.

Mais l'algorithme est naif, simple Ã  comprendre et Ã  implÃ©menter. :D

## Algorithme CUDA

> Version non fonctionnelle, voir les explications plus bas

```cpp
// Etape 1 : ajout des parties CUDA
__global__ void reduce(float* tab, int n)
{
    // Chaque thread va executer le code ici
    // Il faut donc s'assurer que le contenu est correct, OK ici (avec synchronisation)

    int m = n >> 1;

    while (m > 0)
    {
        ecrasement(tab, m);
        m = m >> 1;

        // Ici il faut rajouter le fait d'attendre que tous les threads aient fini leur travail (Ã©crasement en cours)
        __syncthreads();
    }
}

__device__ void ecrasement (float* tab, int m)
{
    // Chaque thread va executer le code ici
    // Il faut donc s'assurer que le contenu est correct, 
    // Ici il faut retirer la boucle for et remplacer par l'ID du thread

    const int TID = Thread2D.getTID();
    if (TID < m)
    {
        tab[TID] = tab[TID] + tab[TID + m];
    }
}
```

### Malheureusement, Ã§a ne marche pas

`syncthreads()` ne fonctionne pas comme attendu. En pratique `syncthreads()` n'attend **que les** thread du **mÃªme** bloc.

> On imagine les filiÃ¨re infirmiÃ¨re, ingÃ©nieur, etc comme des blocs de thread. `__syncthreads()` appelÃ© dans un bloc `ingÃ©nieur` n'attendra que sur les thread du bloc `ingÃ©nieur`, il n'attendra pas les `infirmiÃ¨res`.

==>> Il n'est pas possible de synchroniser cotÃ© device...

### Solution
Faire fonctionner `reduce` cotÃ© host et `ecrasement` comme global.

```cpp
// Etape 1 : ajout des parties CUDA
__host__ void reduce(float* tabGM, int n)
{
    // Ce code n'est plus executÃ© par tous les threads
    // Il faut ajouter les instructions "dg db"

    dim3 dg(m, 1, 1);
    dim3 db(1, 1, 1); // On emploie que 1 coeur par multiprocesseur --> beaucoup de chÃ´meur
    // Si on mettrait dg(1,1,1) et db(m,1,1) on aurait un seul thread qui ferait tout le travail. De plus "m" ne pourrais pas Ãªtre supÃ©rieur Ã  1024 (taille max d'un bloc)
    // Comme amÃ©lioration, on pourrait factoriser "m" par a et b, et mettre dg(a,1,1) et db(b,1,1) pour avoir a*b threads. Si on fait Ã§a, il faut aussi adapter le code pour rÃ©duire des fois dg, des fois db.

    int m = n >> 1;

    while (m > 0)
    {
        // Note : Il faut Ã©viter de transmettre de l'information sur le PSIe (arguments)... ici tab et m ont une taille nÃ©gligeable (une 12Ã¨ne d'octets) donc c'est bon
        ecrasement<<<dg,db>>>(tabGM, m);
        // Pas de problÃ¨me de concurrence ici, car on est cotÃ© host :
        // BarriÃ¨re de synchronisation implicite, le driver NVidia va attentre que le kernel prÃ©cÃ©dant soit terminÃ© (donc qu'un seul kernel (global) Ã  la fois, si un kernel est en cours, on attend qu'il soit terminÃ©)
        // De mÃªme, si on a un "memcopy" on veut copier les rÃ©sultats du kernel, donc un memcopy attend que le kernel soit terminÃ© avant de passer Ã  la suite du code

        m = m >> 1;

        dg.x = dg.x / 2; // On est cotÃ© host, ici on aura pas bc de performance Ã  perdre, car l'host est par nature lent
    }
}

__global__ void ecrasement (float* tabGM, int m)
{
    // Chaque thread va executer le code ici
    // Il faut donc s'assurer que le contenu est correct, 
    // Ici il faut retirer la boucle for et remplacer par l'ID du thread

    const int TID = Thread2D.getTID();
    if (TID < m)
    {
        tabGM[TID] = tabGM[TID] + tabGM[TID + m];
    }
}
```
