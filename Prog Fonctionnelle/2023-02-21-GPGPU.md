# Historique

GPGPU : General Purpose Computing on Graphics Processing Units

Les processeurs ont une architecture SIMT : Single Instruction Multiple Thread
- Les m√™mes instructions sont ex√©cut√©es sur plusieurs threads en m√™me temps	

Utiliser le GPU
- `CUDA` : Permet d'utiliser les GPU pour faire du calcul. Il s'agit d'un langage de programmation pour les GPU qui permet de faire de tout (rendu graphique, traitement de donn√©es, calculs scientifiques, etc) dans le paradigme de `programmation parall√®le orient√© donn√©e`. (Appartient √† NVidia) (li√© au mat√©riel)
- `OpenCL` (n'est plus utilis√© de nos jours) (C'est une API, et non un langage de programmation) (n'est pas li√© au mat√©riel)

`CUDNN` : Librairie de `CUDA` pour faire des r√©seaux de neurones (Neural Network)

En analogie : `CUDA` est le `C++` des GPU; `OpenCL` est le `Java` des GPU --> CUDA est plus performant que OpenCL, car plus proche du mat√©riel.

# CUDA

- Se base sur le langage `C++`, avec des symboles `K balistiques` sp√©cifiques
- Compilateur `nvcc` (NVIDIA CUDA Compiler) (pour les symboles) et `gcc` pour le code `C++`
- extension `.cu` et `.h`

# Vocabulaire

Terme utilis√© | Equivalent | Description
--- | --- | ---
Host, client | `CPU` | Central Processing Unit
Device, serveur | `GPU` | Graphics Processing Unit

Le CPU utilise la **RAM**, et le GPU la **GRAM**

Le CPU est connect√© au GPU par le bus **PCI Express**. Dans notre cas il s'agit d'un GEN3x16x16 (16 connecteurs physique, 16 connecteurs c√¢bl√©s) <span style="color: #46b7ae; font-style: italic; font-size: 0.85rem">// Si on nous donne un `GEN3x16` !! sa signifie certainement que certains connecteurs ne sont pas utilisables</span> 

## D√©bit

Le bus √† un d√©bit de 16 Gigabyte/secondes, mais 12 utile (ent√™te, corps, etc) (bidirectionnel, on a 2 bus))

La RAM √† une bande passente de 5 Go/s (ordre de grandeur pour notre serveur CUDA3)
La GRAM √† une bande passente de 600 Go/s (ordre de grandeur pour notre serveur CUDA3)

<span style="color: red">--> !! Au goulot d'√©tranglement qui est le PCIe</span> 

# Symboles CUDA (KBalistiques)
Fichiers `*.cu`
```c++
__host__ void use()
{
    // Code execut√© sur le CPU

    // Ne peut pas faire appel √† une fonction "__device__"
}

__global__ void kernel() // Void obligatoire, car on appel cette fonction de mani√®re asynchrone --> Aucun retour possible
{
    // Code execut√© sur le GPU
    // Execut√© en parall√®le par tous les threads
    // Pour faire varier les donn√©es --> Pattern d'entrelacement √† √©crire ici.

    // Ne peut √™tre appel√© que par une fonction "__host__"
    // Ne peut pas faire appel √† une fonction "__host__"
}

__device__ void secondaire() // Toutes fonctions secondaires (exemple "work(i)") est pr√©c√©d√© par "__device__"
{
    // Code execut√© sur le GPU

    // Ne peut √™tre appel√© que par une fonction "__global__"
    // Ne peut pas √™tre appel√© par une fonction "__host__"
    // Ne peut pas faire appel √† une fonction "__host__"
}
```

pour appeler un **kernel** :
```c++	
__host__ void use()
{
    dim3 dg(2,3,1); // 2 blocs de 3 threads
    dim3 db(4,2,1); // 4 threads par blocs
    // (2 * 3 * 1) * (4 * 2 * 1) = 48 threads

    kernel<<<dg, db>>>(...); // Asynchrone : n'attend pas la fin de l'ex√©cution du kernel pour continuer le code du bloc
}
```

<span style="color: red">!! Le serveur (GPU) (global ou device) ne peut pas appeler le client (CPU) (host)</span>.
Analogie : un serveur d'impression ne va pas demander au client √† 3h du matin pour lui demander s'il veut imprimer un document.
<span style="color: red">Le "__device__" ne peut pas √™tre appel√© par l'host.</span>.
En d'autre termes, "host" est le chef d'orchestre, "global" le musicien, "device" l'instrument du musicien.

# Mod√®le de programmation CUDA

Un mod√®le permet de faire une abstraction de la r√©alit√© pour simplifier sa compr√©hension.
- Un mod√®le simplifie la r√©alit√© --> Il est donc "faux"

![Mod√®le CUDA](./Export/Mod%C3%A8le%20GPU.drawio.svg)

# Structure de donn√©es
DG : Dimension Grid
DB : Dimension Block

![Structure de donn√©es](./Export/schema-Cuda%20DG%20DB.drawio.svg)

Nous avons donc une structure de donn√©es sous forme d'arbre :
  - 3 niveaux :
    - 1er niveau (racine) : la grille
    - 2√®me niveau : les blocs
    - 3√®me niveau (feuille) : les threads

--> Hi√©rarchie parent-enfant

on pourrait avoir des tableaux 1D (ex addition vecteurs), 2D (ex √©cran), 3D (ex voxels)

<span style="color: #46b7ae; font-style: italic; font-size: 0.85rem">// Rien n'oblige d'avoir les m√™mes dimensions pour le `dg` et le `db`. Exemple, l'un peut √™tre 1D et l'autre 3D</span> 

Si l'on voudrais utiliser de la 3D, il faudrais sp√©cifi√© la 3√®me composante de `dg` et `db`. La valeur √† 1 signifie que l'on utilise pas cette dimension. <span style="color: #46b7ae; font-style: italic; font-size: 0.85rem">// Ne pas mettre la valeur 0, sinon nous aurions une multiplication par 0 !!</span> 

<span style="color: #46b7ae; font-style: italic; font-size: 0.85rem">// pour le cours on fait que du 2D, autant pour le `dg` et me `db`</span> 

# relation avec SDD & le mod√®le
Software || Hardware
--- | --- | ---
Grid | <--> | GPU
Block | <--> | MP
Thread | <--> | Core

**Exemples de valeurs pour `dg` et `db`**
`dg(a,b,c)` // a * b * c = nombre de blocs (si possible le **m√™me nombre de multi processeurs**, ou un **multiple**)
`db(x,y,z)` // x * y * z = nombre de threads (si possible, le **m√™me nombre de coeurs du GPU**, ou un **multiple**)


<!-- #region TODO BLOCK --> 
<div style="margin: 20px auto; padding: 10px; background-color: #ffd48a; border-left: 5px solid #8a5700;color: black; font-size: 2em">
<span> üìù </span>TODO<br>
<span style="font-size: 0.75em">
UM ou MP ? (Micro processeur ou Multi processeur) ?????
</span></div>

<!-- #endregion TODO BLOCK -->



```c++
// Notre machine dispose de 128 processeurs, ayant 64 coeurs chacun

dg(16,8,1) // 16 * 8 = 128 blocs
dg(64,2,1) // 64 * 2 = 128 blocs
db(8,8,1)  // 8 * 8 = 64 threads
db(16,4,1) // 16 * 4 = 64 threads
```

Tant qu'on respecte le mat√©riel, on peut placer les valeurs comme on veut.

Si on ne respecte pas les m√™mes valeurs que le mat√©riel, nous avons des pertes de performances.
Pire des cas, mettre 1 partout, car nous aurions que des "chomeurs" (threads) qui ne font rien, et 1 seul qui travail

# Patterns
`1-1` : 1 thread par "grain de riz" (pixel)
`entrelacement` : 1 thread s'occupe de tous les N "grains de riz" (pixels)

# Heuristiques

<span style="color: #46b7ae; font-style: italic; font-size: 0.85rem">// # == Nombre de </span> 
H1 : [# Thread by block] % [# Core by MP] = 0
H2 : [# Block] % [# MP] = 0

`Hardware::getXXX`

