> <span style="font-size: 1.5em">üìñ</span> <span style="color: orange; font-size: 1.3em;">Pr√©sentation `Classification SVM`</span>
> Support Vector Machine

# Fonction de discrimination lin√©aire
![](Screen/2023-03-24-12-40-11.png)


## Classes multiples

1. 1 fonction = 1 ou 2 classes
2. 2 fonction = 3 ou 4 classes
3. 3 fonction = 5-7 classes
4. 4 fonction = 8-10 classes


# Donn√©es non lin√©aires

![](Screen/2023-03-24-13-18-53.png)

## Hyper param√®tres
### **C** : contr√¥le la marge

![](Screen/2023-03-24-13-19-13.png)

![](Screen/2023-03-24-13-20-29.png)

![](Screen/2023-03-24-13-21-05.png)

![](Screen/2023-03-24-13-22-06.png)
![](Screen/2023-03-24-13-22-17.png)

![](Screen/2023-03-24-13-22-39.png)

# CV : Cross Validation
n = valeur du CV
Exemple si on d√©fini CV=5, on va diviser le dataset en 5 parties et on l'execute 5 fois :
![](Screen/2023-03-24-14-51-51.png)

# Overfitting
> == Sur-entrainement

![Alt text](Export/Overfitting-prob.svg)

cas possible :
- Le mod√®le est mal param√©tr√©
- Les donn√©es de train ne correspondent pas du tout aux donn√©es de test

Pendant l'entrainement, il a appris les choses par coeur --> il ne reconnait pas les nouvelles donn√©es

-->> Solution : **Cross-Validation**

# Cross-Validation

train > validation > test
(validation fait encore partie du train)



![Alt text](Export/Overfitting-sol.svg)

(en g√©n√©ral, on utilise CV5 si on a pas bc de donn√©e, 10 si on en a bc)

Avec les CV, on va chercher √† trouver le meilleur mod√®le possible (avec le meilleur score)

`GridSearchCV` : permet de trouver les meilleurs hyper-param√®tres