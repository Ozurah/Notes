> <span style="font-size: 1.5em">üìñ</span> <span style="color: orange; font-size: 1.3em;">Pr√©sentation ``</span>

p == probabilit√©
$\omega$ = la classe
x = la caract√©ristique

p(x) = probabilit√© de la caract√©ristique x
p($\omega$) = **probabilit√© √† priori** de la classe $\omega$ (g√©n√©ralement connue)

$p(\omega_i|x)$ = **probabilit√© √† posteriori** de la classe $\omega$ sachant la caract√©ristique x

![](Screen/2023-03-17-13-06-42.png)

!!! note remarque sur la derni√®re formule
    **post√©riori = proba conditionelle * proba √† priori**

    Et comme on cherche la "vraisamblance", on a pas besoin de calculer le p(x), car il est pr√©sent pour chaque "w_i"

![](Screen/2023-03-17-13-12-15.png)
![](Screen/2023-03-17-13-12-49.png)

Pour √©viter les "0", on peut appliquer une estimation de la place :
- `+ 1` au num√©rateur
- `+ #c` au d√©nominateur (`#c` = nombre de caract√©ristiques)
![](Screen/2023-03-17-13-15-26.png)

Et on calcul les valeurs pour chaque caract√©ristique :
![](Screen/2023-03-17-13-18-26.png)


Quand on obtient un nouveau document, on va calculer la classe la plus probable pour ce document. La classe est celle qui a la plus grande probabilit√© √† posteriori :
![](Screen/2023-03-17-13-17-50.png)

![](Screen/2023-03-17-13-21-05.png)

# Naive Bayes
Chaque caract√©ristique est repr√©sent√©e par un nombre entier

```python
from sklearn import preprocessing

weather = ['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny','Rainy','Sunny','Overcast','Overcast','Rainy']

le = preprocessing.LabelEncoder()
weather_encoded = le.fit_transform(weather)

print(weather_encoded)

# [2 2 0 1 1 1 0 2 2 1 2 0 0 1]
```

# Gaussian Naive Bayes
Chaque caract√©ristique est repr√©sent√©e par sa probabilit√© gaussienne

Il faut donc calculer la moyenne et l'√©cart-type de chaque caract√©ristique

et apr√®s selon l'exercice, on utilise soit la binomial, soit la gaussienne. Avec des valeurs continues, la gaussienne est plus adapt√©e; mais des valeurs discr√®tes, la binomial est plus adapt√©e

```python
# Import Gaussian Naive Bayes model
from sklearn.naive_bayes import GaussianNB

features = np.column_stack((temp_encoded, weather_encoded))
features.shape

# Create a Gaussian Classifier
model = GaussianNB()

# Entrainement : _Fit_ le jeu de donn√©es sur le classificateur
model.fit(features, label_encoded)

#Predict Output
predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild
print("Predicted Value:", predicted)
if predicted == 0:
    print("With this features (Overcast, Mild) the player will not play")
```

`fit` va calculer toutes les probabilit√©s n√©cessaires pour le classificateur
`predict` va calculer la probabilit√© de chaque classe et donner la plus probable

## TP 5 (Wine)

### Code
```python

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3, random_state=37, stratify=wine.target) # 70% training and 30% test

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()

gnb.fit(x_train, y_train)

y_pred = gnb.predict(x_test)

confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
print("Confusion matrix :")
print(confusion_matrix)
print("Accuracy", metrics.accuracy_score(y_test, y_pred))
```

### A quoi sert stratify
Stratify : permet de garder la m√™me proportion de classes dans les donn√©es d'entrainement et de test

Exemple si on a 40% de classe 1, 10% de classe 2 et 50% de classe 3 dans les donn√©es d'entrainement

On √©vite de prendre que des donn√©es de la classe 3 et aucune de la classe 2

==> Important quand il y a un gros d√©s√©quilibre entre les classes
Si on a des classes style "33% 30% 37%" c'est pas trop important de stratifier


### Matrice de confusion

La matrice de confusion indique le nombre d'erreur de classification

&nbsp; | c1 | c2 | c3
--- | --- | --- | ---
c1 | 17 | 1 | 0
c2 | 0 | 18 | 0
c3 | 1 | 0 | 15

cette matrice indique le nombre de fois o√π l'√©l√©ment a √©t√© plac√© dans la classe c1, c2 ou c3

Comment lire la matrice :
- Pour d√©terminer la classe c1 :
  - 17 √©l√©ments plac√©s dans C1
  - 0 dans C2
  - 1 dans C3
- Pour d√©terminer la classe c2 :
  - 1 √©l√©ment plac√© dans C1
  - 18 dans C2
  - 0 dans C3
- etc

accuracy = somme(diago) / somme(tout) = (17 + 18 + 15) / (17 + 1 + 0 + 0 + 18 + 0 + 1 + 0 + 15) = 0.96 = 96%

# Precision, recall, F1 score
**precision** est la capacit√© du mod√®le √† ne pas pr√©dire de faux positifs

**recall** est la capacit√© du mod√®le √† ne pas pr√©dire de faux n√©gatifs ?

**F1 score** est la moyenne harmonique de la pr√©cision et du rappel
= 2 * (precision * recall) / (precision + recall)
